---
title: "Time-Series"
output: github_document
editor_options: 
  chunk_output_type: inline
---

This is a minimalistic demo on how to model time-series with RNN, including training and inference. 

It relies on an explicit symbolic construction of the RNN cells (LSTM or GRU), thus supporting training on CPU unlike the FusedRNN operator that is CUDA dependent. 

```{r, echo=TRUE, message=F}
library("readr")
library("dplyr")
library("plotly")
library("mxnet")
source("../rnn.graph.R")
```

### Data preparation

```{r, echo=TRUE}
seq_len = 100
samples = 192

seeds <- runif(samples, min = -pi, max = pi)
pts <- sapply(seeds, function(x) sin(x + pi/12 * (0:(seq_len))))

x <- pts[1:seq_len, ]
x <- array(x, dim = c(1, seq_len, samples))
y <- pts[-1, ]

p1 = plot_ly(x = 1:dim(x)[2], y = x[1,,1], type = "scatter", mode = "lines") %>% 
  add_trace(x = 1:dim(x)[2], y = x[1,,2], type = "scatter", mode = "lines") %>% 
  add_trace(x = 1:dim(x)[2], y = x[1,,3], type = "scatter", mode = "lines") %>% 
  add_trace(x = 1:dim(x)[2], y = x[1,,4], type = "scatter", mode = "lines") %>% 
  add_trace(x = 1:dim(x)[2], y = x[1,,5], type = "scatter", mode = "lines")

p2 = plot_ly(x = 1:length(y[,1]), y = y[,1], type = "scatter", mode = "lines") %>%
  add_trace(x = 1:length(y[,2]), y = y[,2], type = "scatter", mode = "lines")

p1
```

### Create data iterators

```{r}
batch.size = 16

train.data <- mx.io.arrayiter(data = x[,,1:160, drop = F], label = y[, 1:160], 
                              batch.size = batch.size, shuffle = TRUE)

eval.data <- mx.io.arrayiter(data = x[,,-(1:160), drop = F], label = y[, -(1:160)], 
                              batch.size = batch.size, shuffle = FALSE)
```


### Model architecture

```{r, echo=TRUE}
symbol <- rnn.graph.unroll(seq_len = 2, 
                           num_rnn_layer =  1, 
                           num_hidden = 50,
                           input_size = NULL,
                           num_embed = NULL, 
                           num_decode = 1,
                           masking = F, 
                           loss_output = "linear",
                           dropout = 0.2, 
                           ignore_label = -1,
                           cell_type = "lstm",
                           output_last_state = F,
                           config = "one-to-one")

graph = graph.viz(symbol, type = "graph", direction = "TD", 
                  shape=list(data = c(1, 2, batch.size), 
                             label = c(2, batch.size)))
```

```{r, echo = FALSE, fig.height=12}
# DiagrammeRsvg::export_svg(graph) %>% charToRaw %>% rsvg::rsvg_png("time_graph.png")
graph
```


```{r, echo = FALSE}
symbol <- rnn.graph.unroll(seq_len = seq_len, 
                           num_rnn_layer =  2, 
                           num_hidden = 50,
                           input_size = NULL,
                           num_embed = NULL, 
                           num_decode = 1,
                           masking = F, 
                           loss_output = "linear",
                           dropout = 0.2, 
                           ignore_label = -1,
                           cell_type = "lstm",
                           output_last_state = F,
                           config = "one-to-one")
```


### Fit a LSTM model

Needs a custom metric to handle labels in a matrix rather than flat format in the iterator. 

```{r}
mx.metric.mse.seq <- mx.metric.custom("Perplexity", function(label, pred) {
  label = mx.nd.reshape(mx.nd.array(label), shape = -1)
  label = as.array(label)
  res <- mean((label-pred)^2)
  return(res)
})
```


```{r, echo=TRUE, eval=TRUE, message=FALSE}
ctx <- mx.cpu()

initializer <- mx.init.Xavier(rnd_type = "gaussian", 
                              factor_type = "avg", 
                              magnitude = 2.5)

optimizer <- mx.opt.create("adadelta", rho = 0.9, eps = 1e-5, wd = 1e-6,
                           clip_gradient = 1, rescale.grad = 1/batch.size)

logger <- mx.metric.logger()
epoch.end.callback <- mx.callback.log.train.metric(period = 10, logger = logger)

system.time(
  model <- mx.model.buckets(symbol = symbol,
                            train.data = train.data, 
                            eval.data = eval.data, 
                            num.round = 50, ctx = ctx, verbose = TRUE,
                            metric = mx.metric.mse.seq, 
                            initializer = initializer, optimizer = optimizer, 
                            batch.end.callback = NULL, 
                            epoch.end.callback = epoch.end.callback)
)
```

```{r, fig.height=5}
plot_ly(x = seq_len(length(logger$train)), y = logger$train, type = "scatter", 
        mode = "markers+lines", name = "train") %>% 
  add_trace(y = logger$eval, type = "scatter", 
            mode = "markers+lines", name = "eval")
```


## Inference on test data

Setup inference data. Need to apply preprocessing to inference sequence and convert into a infer data iterator. 

### Build the inference symbols

Two symbols: 

- first unrolled to the length of the inference sequence. 
- second of length one on which to iterate up to the number of the desired inference steps. 

```{r}
ctx <- mx.cpu()

pred_length = 80
data = mx.nd.array(x[, , 1, drop = F])
infer_length_ini <- dim(data)[2]

symbol.infer.ini <- rnn.graph.unroll(seq_len = infer_length_ini,
                                     num_rnn_layer = 2, 
                                     num_hidden = 50,
                                     input_size = NULL,
                                     num_embed = NULL, 
                                     num_decode = 1,
                                     masking = F, 
                                     loss_output = "linear",
                                     dropout = 0, 
                                     ignore_label = -1,
                                     cell_type = "lstm",
                                     output_last_state = T,
                                     config = "one-to-one")

symbol.infer <- rnn.graph.unroll(seq_len = 1,
                                 num_rnn_layer = 2, 
                                 num_hidden = 50,
                                 input_size = NULL,
                                 num_embed = NULL, 
                                 num_decode = 1,
                                 masking = F, 
                                 loss_output = "linear",
                                 dropout = 0, 
                                 ignore_label = -1,
                                 cell_type = "lstm",
                                 output_last_state = T,
                                 config = "one-to-one")
```


### Inference

```{r, echo=TRUE, eval=TRUE}
predict <- numeric()

infer <- mxnet:::mx.rnn.infer.unroll(data = data, 
                             symbol = symbol.infer.ini,
                             num_hidden = 50,
                             arg.params = model$arg.params,
                             aux.params = model$aux.params,
                             init_states = NULL,
                             ctx = ctx)

pred = mx.nd.array(y[seq_len, 1, drop = F])
real = sin(seeds[1] + pi/12 * (seq_len+1):(seq_len+pred_length))

for (i in 1:pred_length) {
  
  data = mx.nd.reshape(pred, shape = c(1,1,1))
  
  infer <- mxnet:::mx.rnn.infer.unroll(data = data, 
                               symbol = symbol.infer,
                               num_hidden = 50,
                               arg.params = model$arg.params,
                               aux.params = model$aux.params,
                               init_states = infer[-1],
                               ctx = ctx)
  
  pred <- infer[[1]]
  predict <- c(predict, as.numeric(as.array(pred)))
}
```

### Plot predictions against real values

```{r}
data = mx.nd.array(x[, , 1, drop = F])
label = mx.nd.array(y[, 1, drop = F])

plot_ly(x = 1:dim(y)[1], y = y[,1], type = "scatter", mode="lines", name = "hist") %>% 
  add_trace(x = dim(y)[1] + 1:length(real), y = real, type = "scatter", mode="lines", name = "real") %>% 
  add_trace(x = dim(y)[1] + 1:length(predict), y = predict, type = "scatter", mode="lines", name = "pred")
```

