---
title: "RNN made easy with MXNet R"
output: github_document
---

> This tutorial presents an example of application of RNN to texts classification using padded and bucketed data to efficiently handle sequences of varying lengths. It requires running on a GPU with CUDA. 

Example based on sentiment analysis on the [IMDB data](http://ai.stanford.edu/~amaas/data/sentiment/).

Load some packages

```{r, echo=T, message=F}
require("readr")
require("dplyr")
require("plotly")
require("stringr")
require("stringi")
require("scales")
require("mxnet")
```

Load utility functions

```{r, echo=T}
source("mx.io.bucket.iter.nomask.R")
source("rnn.graph.R")
source("model.rnn.R")
source("rnn.infer.R")
```

## Data preparation

Data preparation is performed by the script: `data.preprocessing.R`. 

The following steps are executed: 

- import IMDB.
- pre-process into lists whose elements are the buckets containing the samples and their associated labels. 
- Split each review into word vectors and apply some common cleansing (remove special characters, lower case, remove extra blank space...) 
- Aggregate the buckets of samples and labels into a list


```{r, echo=TRUE}
corpus_bucketed_train <- readRDS(file = "data/train_buckets_one_to_one.rds")
corpus_bucketed_test <- readRDS(file = "data/eval_buckets_one_to_one.rds")

vocab <- length(corpus_bucketed_test$dic)

### Create iterators
batch.size = 32

train.data <- mx.io.bucket.iter(buckets = corpus_bucketed_train$buckets, batch.size = batch.size, data.mask.element = 0, shuffle = TRUE)

eval.data <- mx.io.bucket.iter(buckets = corpus_bucketed_test$buckets, batch.size = batch.size, data.mask.element = 0, shuffle = FALSE)
```

## Model arhcitecture

```{r, echo=TRUE, fig.height=1}
rnn_graph_one_one <- rnn.graph(num.rnn.layer = 2, 
                               num.hidden = 128,
                               input.size=vocab+1,
                               num.embed=64, 
                               num.label=vocab+1,
                               dropout=0, 
                               ignore_label = 0,
                               cell.type="lstm",
                               masking = F,
                               config = "one-to-one")

graph.viz(rnn_graph_one_one, type = "graph", direction = "LR", 
          graph.height.px = 100, graph.width.px = 800, shape=c(100, 64))
```


## Fit a LSTM model

```{r, echo=TRUE, eval=FALSE}
devices <- mx.gpu(0)

initializer <- mx.init.Xavier(rnd_type = "gaussian", factor_type = "in", magnitude = 2)

optimizer <- mx.opt.create("adadelta", rho = 0.92, eps = 1e-6, wd = 1e-8, clip_gradient=2, rescale.grad=1/batch.size)

# optimizer <- mx.opt.create("adam", learning.rate = 0.001, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, wd = 1e-5, rescale.grad = 1/batch.size, clip_gradient = 1)

# optimizer <- mx.opt.create("rmsprop", learning.rate = 0.002, gamma1 = 0.95, gamma2 = 0.95, wd = 1e-5, clip_gradient=1, rescale.grad=1/batch.size)

logger <- mx.metric.logger()
epoch.end.callback <- mx.callback.log.train.metric(period = 1, logger = logger)
batch.end.callback <- mx.callback.log.train.metric(period = 50)


mx.metric.custom_nd <- function(name, feval) {
  init <- function() {
    c(0, 0)
  }
  update <- function(label, pred, state) {
    m <- feval(label, pred)
    state <- c(state[[1]] + 1, state[[2]] + m)
    return(state)
  }
  get <- function(state) {
    list(name=name, value=(state[[2]]/state[[1]]))
  }
  ret <- (list(init=init, update=update, get=get))
  class(ret) <- "mx.metric"
  return(ret)
}

mx.metric.Perplexity <- mx.metric.custom_nd("Perplexity", function(label, pred) {
  label_probs <- as.array(mx.nd.choose.element.0index(pred, label))
  batch <- length(label_probs)
  NLL <- -sum(log(pmax(1e-15, as.array(label_probs)))) / batch
  Perplexity <- exp(NLL)
  return(Perplexity)
})

model <- mx.rnn.buckets(symbol = rnn_graph_one_one,
                        train.data = train.data, eval.data = eval.data,
                        num.round = 24, ctx = devices, verbose = TRUE,
                        metric = mx.metric.Perplexity, 
                        initializer = initializer, optimizer = optimizer, 
                        batch.end.callback = batch.end.callback, 
                        epoch.end.callback = epoch.end.callback)

mx.model.save(model, prefix = "models/model_one_to_one_lstm", iteration = 24)

p <- plot_ly(x = seq_len(length(logger$train)), y = logger$train, type = "scatter", mode = "markers+lines", name = "train") %>% 
  add_trace(y = logger$eval, type = "scatter", mode = "markers+lines", name = "eval")

plotly::export(p, file = "logger_one_to_one.png")
```

![](logger_one_to_one.png)

## Inference on test data

```{r, echo=TRUE}
ctx <- mx.gpu(0)
batch.size <- 64

corpus_bucketed_test <- readRDS(file = "data/corpus_bucketed_test.rds")

test.data <- mx.io.bucket.iter(buckets = corpus_bucketed_test$buckets, batch.size = batch.size, data.mask.element = 0, shuffle = FALSE)
```


### LSTM

```{r, echo=TRUE, eval=TRUE}
model <- mx.model.load(prefix = "models/model_sentiment_lstm", iteration = 10)
infer <- mx.rnn.infer.buckets(infer_iter = test.data, 
                              model = model,
                              ctx = ctx)

pred_raw <- t(as.array(infer))
pred <- max.col(pred_raw, tie = "first") - 1
label <- unlist(lapply(corpus_bucketed_test$buckets, function(x) x$label))

acc <- sum(label == pred)/length(label)
roc <- roc(predictions = pred_raw[, 2], labels = factor(label))
auc <- auc(roc)

```


